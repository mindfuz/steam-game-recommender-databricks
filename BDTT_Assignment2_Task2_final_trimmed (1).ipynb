{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cba27905-4b49-441c-adbb-663dcde61004",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3e44714-e2bf-42e9-a563-ff8aeb973a90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In this task, we will build a collaborative filtering recommender system using user data from Steam, a gaming platform. The dataset has four attributes: the user ID, game, user behaviour, and playtime (if the behaviour is play). This data allows us to infer user preferences in the absence of concrete, explicit ratings given by users towards games.\n",
    "\n",
    "\n",
    "The main goal is to develop a personalised recommender system which uses previous interaction history between user and games to determine which games a user might enjoy in future. The end result should show a list of N games linked to a specific user_id tailored to the userâ€™s unique profile. As the Steam dataset is 200,000 rows, Spark is a good module to use as this can be considered Big Data.\n",
    "\n",
    "\n",
    "We will use Alternating Least Squares (ALS) algorithm for matrix factorisation, before analysing the performance of the algorithm using metrics such as RMSE and Precision@10. There will also be some examples of hyperparameter tuning, and all of the experiments will be tracked using MLflow. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a61ed944-b308-4526-a35a-bce6c2feb7ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting mlflow\n  Downloading mlflow-2.22.1-py3-none-any.whl (29.0 MB)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (3.5.1)\nCollecting sqlalchemy<3,>=1.4.0\n  Downloading sqlalchemy-2.0.41-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\nCollecting graphene<4\n  Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (1.7.3)\nCollecting docker<8,>=4.0.0\n  Downloading docker-7.1.0-py3-none-any.whl (147 kB)\nRequirement already satisfied: numpy<3 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (1.21.5)\nRequirement already satisfied: pyarrow<20,>=4.0.0 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (7.0.0)\nCollecting Flask<4\n  Downloading flask-3.1.1-py3-none-any.whl (103 kB)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (1.0.2)\nCollecting gunicorn<24\n  Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\nCollecting markdown<4,>=3.3\n  Downloading markdown-3.8-py3-none-any.whl (106 kB)\nRequirement already satisfied: pandas!=2.3.0,<3 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (1.4.2)\nCollecting alembic!=1.10.0,<2\n  Downloading alembic-1.16.1-py3-none-any.whl (242 kB)\nCollecting mlflow-skinny==2.22.1\n  Downloading mlflow_skinny-2.22.1-py3-none-any.whl (6.3 MB)\nRequirement already satisfied: Jinja2<4,>=2.11 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (2.11.3)\nCollecting gitpython<4,>=3.1.9\n  Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\nCollecting sqlparse<1,>=0.4.0\n  Downloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /databricks/python3/lib/python3.9/site-packages (from mlflow-skinny==2.22.1->mlflow) (4.1.1)\nRequirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.9/site-packages (from mlflow-skinny==2.22.1->mlflow) (2.27.1)\nCollecting opentelemetry-api<3,>=1.9.0\n  Downloading opentelemetry_api-1.34.0-py3-none-any.whl (65 kB)\nRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.9/site-packages (from mlflow-skinny==2.22.1->mlflow) (8.0.4)\nCollecting pydantic<3,>=1.10.8\n  Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\nCollecting opentelemetry-sdk<3,>=1.9.0\n  Downloading opentelemetry_sdk-1.34.0-py3-none-any.whl (118 kB)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /databricks/python3/lib/python3.9/site-packages (from mlflow-skinny==2.22.1->mlflow) (3.19.4)\nCollecting uvicorn<1\n  Downloading uvicorn-0.34.3-py3-none-any.whl (62 kB)\nCollecting fastapi<1\n  Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\nCollecting cloudpickle<4\n  Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\nCollecting importlib_metadata!=4.7.0,<9,>=3.7.0\n  Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\nCollecting pyyaml<7,>=5.1\n  Downloading PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (737 kB)\nCollecting databricks-sdk<1,>=0.20.0\n  Downloading databricks_sdk-0.56.0-py3-none-any.whl (733 kB)\nCollecting cachetools<6,>=5.0.0\n  Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\nRequirement already satisfied: packaging<25 in /databricks/python3/lib/python3.9/site-packages (from mlflow-skinny==2.22.1->mlflow) (21.3)\nRequirement already satisfied: tomli in /databricks/python3/lib/python3.9/site-packages (from alembic!=1.10.0,<2->mlflow) (1.2.2)\nCollecting typing-extensions<5,>=4.0.0\n  Downloading typing_extensions-4.14.0-py3-none-any.whl (43 kB)\nCollecting Mako\n  Downloading mako-1.3.10-py3-none-any.whl (78 kB)\nCollecting google-auth~=2.0\n  Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\nCollecting requests<3,>=2.17.3\n  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\nRequirement already satisfied: urllib3>=1.26.0 in /databricks/python3/lib/python3.9/site-packages (from docker<8,>=4.0.0->mlflow) (1.26.9)\nCollecting starlette<0.47.0,>=0.40.0\n  Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\nCollecting markupsafe>=2.1.1\n  Downloading MarkupSafe-3.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\nCollecting Jinja2<4,>=2.11\n  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\nCollecting blinker>=1.9.0\n  Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\nCollecting werkzeug>=3.1.0\n  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\nCollecting itsdangerous>=2.2.0\n  Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\nCollecting click<9,>=7.0\n  Downloading click-8.1.8-py3-none-any.whl (98 kB)\nCollecting gitdb<5,>=4.0.1\n  Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\nCollecting smmap<6,>=3.0.1\n  Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\nCollecting rsa<5,>=3.1.4\n  Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\nCollecting pyasn1-modules>=0.2.1\n  Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\nRequirement already satisfied: python-dateutil<3,>=2.7.0 in /databricks/python3/lib/python3.9/site-packages (from graphene<4->mlflow) (2.8.2)\nCollecting graphql-core<3.3,>=3.1\n  Downloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\nCollecting graphql-relay<3.3,>=3.1\n  Downloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\nCollecting zipp>=3.20\n  Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\nRequirement already satisfied: pyparsing>=2.2.1 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (3.0.4)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (1.3.2)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (9.0.1)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (4.25.0)\nCollecting opentelemetry-semantic-conventions==0.55b0\n  Downloading opentelemetry_semantic_conventions-0.55b0-py3-none-any.whl (196 kB)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.9/site-packages (from pandas!=2.3.0,<3->mlflow) (2021.3)\nCollecting pyasn1<0.7.0,>=0.6.1\n  Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\nCollecting annotated-types>=0.6.0\n  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\nCollecting typing-inspection>=0.4.0\n  Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\nCollecting pydantic-core==2.33.2\n  Downloading pydantic_core-2.33.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\nRequirement already satisfied: six>=1.5 in /databricks/python3/lib/python3.9/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.1->mlflow) (2021.10.8)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.1->mlflow) (3.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.1->mlflow) (2.0.4)\nRequirement already satisfied: joblib>=0.11 in /databricks/python3/lib/python3.9/site-packages (from scikit-learn<2->mlflow) (1.1.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from scikit-learn<2->mlflow) (2.2.0)\nCollecting greenlet>=1\n  Downloading greenlet-3.2.3-cp39-cp39-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (580 kB)\nCollecting anyio<5,>=3.6.2\n  Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\nCollecting sniffio>=1.1\n  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\nCollecting exceptiongroup>=1.0.2\n  Downloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\nCollecting h11>=0.8\n  Downloading h11-0.16.0-py3-none-any.whl (37 kB)\nInstalling collected packages: zipp, typing-extensions, sniffio, pyasn1, importlib-metadata, exceptiongroup, typing-inspection, smmap, rsa, pydantic-core, pyasn1-modules, opentelemetry-api, cachetools, anyio, annotated-types, starlette, requests, pydantic, opentelemetry-semantic-conventions, markupsafe, h11, greenlet, graphql-core, google-auth, gitdb, click, werkzeug, uvicorn, sqlparse, sqlalchemy, pyyaml, opentelemetry-sdk, Mako, Jinja2, itsdangerous, graphql-relay, gitpython, fastapi, databricks-sdk, cloudpickle, blinker, mlflow-skinny, markdown, gunicorn, graphene, Flask, docker, alembic, mlflow\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 4.1.1\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3de63bb6-26ba-4bcf-b70c-da22ae5a92c9\n    Can't uninstall 'typing-extensions'. No files were found to uninstall.\n  Attempting uninstall: requests\n    Found existing installation: requests 2.27.1\n    Not uninstalling requests at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3de63bb6-26ba-4bcf-b70c-da22ae5a92c9\n    Can't uninstall 'requests'. No files were found to uninstall.\n  Attempting uninstall: markupsafe\n    Found existing installation: MarkupSafe 2.0.1\n    Not uninstalling markupsafe at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3de63bb6-26ba-4bcf-b70c-da22ae5a92c9\n    Can't uninstall 'MarkupSafe'. No files were found to uninstall.\n  Attempting uninstall: click\n    Found existing installation: click 8.0.4\n    Not uninstalling click at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3de63bb6-26ba-4bcf-b70c-da22ae5a92c9\n    Can't uninstall 'click'. No files were found to uninstall.\n  Attempting uninstall: Jinja2\n    Found existing installation: Jinja2 2.11.3\n    Not uninstalling jinja2 at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-3de63bb6-26ba-4bcf-b70c-da22ae5a92c9\n    Can't uninstall 'Jinja2'. No files were found to uninstall.\nSuccessfully installed Flask-3.1.1 Jinja2-3.1.6 Mako-1.3.10 alembic-1.16.1 annotated-types-0.7.0 anyio-4.9.0 blinker-1.9.0 cachetools-5.5.2 click-8.1.8 cloudpickle-3.1.1 databricks-sdk-0.56.0 docker-7.1.0 exceptiongroup-1.3.0 fastapi-0.115.12 gitdb-4.0.12 gitpython-3.1.44 google-auth-2.40.3 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 greenlet-3.2.3 gunicorn-23.0.0 h11-0.16.0 importlib-metadata-8.7.0 itsdangerous-2.2.0 markdown-3.8 markupsafe-3.0.2 mlflow-2.22.1 mlflow-skinny-2.22.1 opentelemetry-api-1.34.0 opentelemetry-sdk-1.34.0 opentelemetry-semantic-conventions-0.55b0 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.5 pydantic-core-2.33.2 pyyaml-6.0.2 requests-2.32.3 rsa-4.9.1 smmap-5.0.2 sniffio-1.3.1 sqlalchemy-2.0.41 sqlparse-0.5.3 starlette-0.46.2 typing-extensions-4.14.0 typing-inspection-0.4.1 uvicorn-0.34.3 werkzeug-3.1.3 zipp-3.23.0\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "%pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec3d37b1-e577-4a64-8972-1560193d22e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import all the necessary libraries\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.mllib.evaluation import RankingMetrics\n",
    "\n",
    "import mlflow\n",
    "import logging\n",
    "import mlflow.spark\n",
    "\n",
    "from pyspark.sql.functions import col, countDistinct, count, when, avg, explode, collect_list, log1p\n",
    "\n",
    "from pyspark.sql.functions import sum as sum_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59f1a50c-1716-4d73-983a-4d488738ec15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logging.getLogger(\"mlflow\").setLevel(logging.ERROR)\n",
    "mlflow.pyspark.ml.autolog()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "909a1775-eb6b-47e5-b42f-abdf30ab4076",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Data Overview\n",
    "\n",
    "The dataset used for this project is `steam-200k.csv`, which contains 200,000 records of user-game interactions collected from the Steam platform. The attributes are as follows:\n",
    "\n",
    "- **user_id**: A unique identifier for each user.\n",
    "- **game**: The title of the game involved in the interaction.\n",
    "- **behaviour**: The action performed by the user towards the game. This is either `purchase` or `play`.\n",
    "- **value**: For `purchase` interactions, this is set to 1, while for `play` interactions, this is set to the number of hours played.\n",
    "\n",
    "The first three attributes should make up a primary key for this table, but there might be anomalies for games with downloadable content or games which have been gifted to friends. These interactions are treated as implicit feedback as there are no ratings given by the users.\n",
    "\n",
    "Having an overview of the data ensures that we know what to look for in the exploratory data analysis section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d79724a-f965-42bc-a02d-24d44a8da2fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"dbfs:/FileStore/tables/steam_200k.csv\", inferSchema=True)\n",
    "df = df.withColumnRenamed(\"_c0\", \"user_id\") \\\n",
    "       .withColumnRenamed(\"_c1\", \"game\") \\\n",
    "       .withColumnRenamed(\"_c2\", \"behaviour\") \\\n",
    "       .withColumnRenamed(\"_c3\", \"value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a05cd18b-9e0a-450c-b51f-c072b410c952",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[4]: [Row(user_id=151603712, game='The Elder Scrolls V Skyrim', behaviour='purchase', value=1.0),\n Row(user_id=151603712, game='The Elder Scrolls V Skyrim', behaviour='play', value=273.0),\n Row(user_id=151603712, game='Fallout 4', behaviour='purchase', value=1.0),\n Row(user_id=151603712, game='Fallout 4', behaviour='play', value=87.0),\n Row(user_id=151603712, game='Spore', behaviour='purchase', value=1.0),\n Row(user_id=151603712, game='Spore', behaviour='play', value=14.9),\n Row(user_id=151603712, game='Fallout New Vegas', behaviour='purchase', value=1.0),\n Row(user_id=151603712, game='Fallout New Vegas', behaviour='play', value=12.1),\n Row(user_id=151603712, game='Left 4 Dead 2', behaviour='purchase', value=1.0),\n Row(user_id=151603712, game='Left 4 Dead 2', behaviour='play', value=8.9)]"
     ]
    }
   ],
   "source": [
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e293c283-405b-455a-9d8f-0cf9ac74d55d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Exploratory Data Analysis (EDA)\n",
    "\n",
    "Verifying the validity of the data is crucial before moving on to developing the recommender system. Firstly, we discovered some basic information about the data, specifically around the user_ids and games. \n",
    "\n",
    "The dataset contains:\n",
    "- **Number of unique users**: 12393\n",
    "- **Number of unique games**: 5155\n",
    "- **Distribution of behaviour**: ~65% `purchase` entries and ~35% `play` entries  \n",
    "\n",
    "This final point was expected, as a game has to be purchased before it is played on.\n",
    "\n",
    "We then split the dataset into two separate dataframes: one where the behaviour was `play` and one for `purchase`. This would allow us to see how users interact with games, and how these interactions might become more apparent during preprocessing and modelling.\n",
    "\n",
    "Using the â€˜playâ€™ dataframe, we checked for the top games by average playtime. The top two were Eastside Hockey Manager and Baldurâ€™s Gate II, with many Football Manager titles taking up the spots from 3-12. A good recommender system might bundle these manager titles together for specific users.\n",
    "\n",
    "To validate data integrity of the dataset, we then searched for duplicate rows. As we touched upon earlier, if a row has the same user_id, game name, and behaviour, then it is a duplicate row and should be analysed further.\n",
    "\n",
    "- **719** duplicate rows across the entire df\n",
    "- **12** of these duplicate rows were where â€˜behaviourâ€™ = â€˜playâ€™\n",
    "- **707** duplicate purchase entries\n",
    "\n",
    "This could be explained by bundle purchases including downloadable content, or it might be a problem with the Steam software logging redundant entries. I made the decision to remove all of the duplicate purchase entries while keeping the multiple play entries, as these represent actual user engagement. This would remove 707 rows, and prepare the newly cleaned dataset for modelling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95f78fdf-cf25-480b-b35a-1a474ba57ecf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 12393\nNumber of unique games: 5155\n+---------+------+\n|behaviour| count|\n+---------+------+\n| purchase|129511|\n|     play| 70489|\n+---------+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Number of unique users\n",
    "num_users = df.select(\"user_id\").distinct().count()\n",
    "print(f\"Number of unique users: {num_users}\")\n",
    "\n",
    "# Number of unique games\n",
    "num_games = df.select(\"game\").distinct().count()\n",
    "print(f\"Number of unique games: {num_games}\")\n",
    "\n",
    "# Proportion of 'purchase' vs 'play'\n",
    "behavior_counts = df.groupBy(\"behaviour\").count()\n",
    "behavior_counts.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11b0fe0e-9178-48c1-a2c1-8a2e35a7e69c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter only \"play\" and \"purchase\" behaviour\n",
    "play_df = df.filter(df.behaviour == \"play\")\n",
    "purchase_df = df.filter(df.behaviour == \"purchase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8772492-4a02-47a3-8816-4720c4662e9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------+------------------+\n|game                                          |avg_playtime      |\n+----------------------------------------------+------------------+\n|Eastside Hockey Manager                       |1295.0            |\n|Baldur's Gate II Enhanced Edition             |475.2555555555556 |\n|FIFA Manager 09                               |411.0             |\n|Perpetuum                                     |400.975           |\n|Football Manager 2014                         |391.9846153846154 |\n|Football Manager 2012                         |390.45316455696195|\n|Football Manager 2010                         |375.04857142857145|\n|Football Manager 2011                         |365.7032258064516 |\n|Freaking Meatbags                             |331.0             |\n|Out of the Park Baseball 16                   |330.4             |\n|Football Manager 2015                         |315.364935064935  |\n|Football Manager 2013                         |310.6596153846154 |\n|FINAL FANTASY XIV A Realm Reborn              |300.84090909090907|\n|Worldwide Soccer Manager 2009                 |295.0             |\n|X-Plane 10 Global - 64 Bit                    |268.025           |\n|NOBUNAGA'S AMBITION Kakushin with Power Up Kit|267.0             |\n|Counter-Strike                                |236.37517605633798|\n|Counter-Strike Global Offensive               |234.40203340595505|\n|FIFA Manager 11                               |229.0             |\n|Avernum 4                                     |228.0             |\n+----------------------------------------------+------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Group by game and calculate average playtime\n",
    "avg_playtime = (\n",
    "    play_df.groupBy(\"game\")\n",
    "           .agg(avg(\"value\").alias(\"avg_playtime\"))\n",
    "           .orderBy(col(\"avg_playtime\").desc())\n",
    ")\n",
    "\n",
    "# Show top 20 most played (on average)\n",
    "avg_playtime.show(20, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0b5ec4f-4fe1-46c5-bd7f-bcdd1846c434",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>user_id</th><th>game</th><th>behaviour</th><th>count</th></tr></thead><tbody><tr><td>11373749</td><td>Sid Meier's Civilization IV Warlords</td><td>purchase</td><td>2</td></tr><tr><td>2259650</td><td>Grand Theft Auto Vice City</td><td>purchase</td><td>2</td></tr><tr><td>164561444</td><td>Sid Meier's Civilization IV Beyond the Sword</td><td>purchase</td><td>2</td></tr><tr><td>2259650</td><td>Sid Meier's Civilization IV</td><td>purchase</td><td>2</td></tr><tr><td>81585721</td><td>Grand Theft Auto III</td><td>purchase</td><td>2</td></tr><tr><td>31733621</td><td>Sid Meier's Civilization IV Colonization</td><td>purchase</td><td>2</td></tr><tr><td>84513749</td><td>Sid Meier's Civilization IV Colonization</td><td>purchase</td><td>2</td></tr><tr><td>64787956</td><td>Grand Theft Auto Vice City</td><td>purchase</td><td>2</td></tr><tr><td>100351493</td><td>Sid Meier's Civilization IV Warlords</td><td>purchase</td><td>2</td></tr><tr><td>33865373</td><td>Grand Theft Auto III</td><td>purchase</td><td>2</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         11373749,
         "Sid Meier's Civilization IV Warlords",
         "purchase",
         2
        ],
        [
         2259650,
         "Grand Theft Auto Vice City",
         "purchase",
         2
        ],
        [
         164561444,
         "Sid Meier's Civilization IV Beyond the Sword",
         "purchase",
         2
        ],
        [
         2259650,
         "Sid Meier's Civilization IV",
         "purchase",
         2
        ],
        [
         81585721,
         "Grand Theft Auto III",
         "purchase",
         2
        ],
        [
         31733621,
         "Sid Meier's Civilization IV Colonization",
         "purchase",
         2
        ],
        [
         84513749,
         "Sid Meier's Civilization IV Colonization",
         "purchase",
         2
        ],
        [
         64787956,
         "Grand Theft Auto Vice City",
         "purchase",
         2
        ],
        [
         100351493,
         "Sid Meier's Civilization IV Warlords",
         "purchase",
         2
        ],
        [
         33865373,
         "Grand Theft Auto III",
         "purchase",
         2
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "user_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "game",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "behaviour",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "count",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Group by the three key columns and count occurrences\n",
    "df.groupBy(\"user_id\", \"game\", \"behaviour\") \\\n",
    "  .count() \\\n",
    "  .filter(\"count > 1\") \\\n",
    "  .limit(10).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "618e9556-e09f-47d1-8a30-4375dea8d382",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------------------+---------+-----+\n|user_id  |game                        |behaviour|value|\n+---------+----------------------------+---------+-----+\n|118664413|Grand Theft Auto San Andreas|play     |1.9  |\n|118664413|Grand Theft Auto San Andreas|play     |0.2  |\n|50769696 |Grand Theft Auto San Andreas|play     |10.9 |\n|50769696 |Grand Theft Auto San Andreas|play     |3.1  |\n|71411882 |Grand Theft Auto III        |play     |1.1  |\n+---------+----------------------------+---------+-----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Group play_df by user_id and game, then count\n",
    "duplicate_plays = play_df.groupBy(\"user_id\", \"game\") \\\n",
    "                         .count() \\\n",
    "                         .filter(\"count > 1\")\n",
    "\n",
    "# Join to original play_df to see the actual duplicate rows\n",
    "duplicate_play_rows = play_df.join(duplicate_plays.drop(\"count\"), on=[\"user_id\", \"game\"], how=\"inner\")\n",
    "\n",
    "# Show results\n",
    "duplicate_play_rows.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd144fa0-7968-4aec-a47e-02ee0ed59ce1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------------------------------+---------+-----+\n|user_id |game                                        |behaviour|value|\n+--------+--------------------------------------------+---------+-----+\n|11373749|Sid Meier's Civilization IV                 |purchase |1.0  |\n|11373749|Sid Meier's Civilization IV                 |purchase |1.0  |\n|11373749|Sid Meier's Civilization IV Beyond the Sword|purchase |1.0  |\n|11373749|Sid Meier's Civilization IV Beyond the Sword|purchase |1.0  |\n|11373749|Sid Meier's Civilization IV Warlords        |purchase |1.0  |\n+--------+--------------------------------------------+---------+-----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Group purchase_df by user_id and game, then count\n",
    "duplicate_purchases = purchase_df.groupBy(\"user_id\", \"game\") \\\n",
    "                         .count() \\\n",
    "                         .filter(\"count > 1\")\n",
    "\n",
    "# Join to original purchase_df to see the actual duplicate rows\n",
    "duplicate_purchase_rows = purchase_df.join(duplicate_purchases.drop(\"count\"), on=[\"user_id\", \"game\"], how=\"inner\")\n",
    "\n",
    "# Show results\n",
    "duplicate_purchase_rows.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f543e5f1-8798-41b3-9905-ff26825fcc25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop duplicate purchases where user_id + game are the same\n",
    "clean_purchase_df = purchase_df.dropDuplicates([\"user_id\", \"game\"])\n",
    "\n",
    "# Combine clean purchases back with original plays\n",
    "df_cleaned = clean_purchase_df.union(play_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df7224eb-13f3-4fb1-abfc-69fdee1b38fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+----------------+---------+------------------+\n|summary|            user_id|            game|behaviour|             value|\n+-------+-------------------+----------------+---------+------------------+\n|  count|             199293|          199293|   199293|            199293|\n|   mean| 1.03718100450071E8|           140.0|     null|17.934246561595128|\n| stddev|7.212047654050417E7|             0.0|     null|138.29795241565554|\n|    min|               5250|     007 Legends|     play|               0.1|\n|    max|          309903146|theHunter Primal| purchase|           11754.0|\n+-------+-------------------+----------------+---------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df_cleaned.describe().show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d2c055e-3735-4459-8b82-6024fcd0ba9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Data Preprocessing and Feature Engineering\n",
    "\n",
    "To prepare the dataset for training a filtering model, we need to construct a singular rating which will act as the combined value for each user-game interaction. We are relying on the implicit feedback mentioned before, which includes playtime and purchase habits. \n",
    "\n",
    "A new column called `rating` was created, and the value was calculated as follows:\n",
    "\n",
    "- If the user purchased the game, the rating is set to 1, indicating clear interest in the game.\n",
    "- If the user played the game, a logarithmic transformation `log1p` is applied to the playtime in hours. This transformation:\n",
    "  - compresses very large values, reducing the effect of outliers\n",
    "  - preserves the structure of engagement (more hours still gives a higher rating)\n",
    "\n",
    "After this change, the new dataframe will have adjusted ratings for each combination of user_id and game, which reflect the userâ€™s interest in the game. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43225316-a708-4682-9bf6-ea13bab93e4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n|summary|             rating|\n+-------+-------------------+\n|  count|             199293|\n|   mean| 1.3724203573639617|\n| stddev| 1.0847619258183574|\n|    min|0.09531017980432487|\n|    max|   9.37203396097417|\n+-------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "ratings = df_cleaned.withColumn(\"rating\",\n",
    "    when(col(\"behaviour\")==\"purchase\", 1.0)\n",
    "   .otherwise(log1p(col(\"value\")))\n",
    ").select(\"user_id\", \"game\", \"rating\")\n",
    "ratings.cache()\n",
    "ratings.describe(\"rating\").show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad1f30f3-bbfe-4b2b-a434-9ac94732a2ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Indexing the `game` Column\n",
    "\n",
    "Before training the ALS model, we must convert the important categorical features (such as game names) into numerical IDs, as ALS requires integer-based identifiers. That meant employing the `StringIndexer` on the `game` column, encoding each game into a newly created `game_id`. The `game_id` column was then cast to integer type to ensure that it was compatible with ALS.\n",
    "\n",
    "We then checked the first 5 rows of this new dataframe `indexed` which had the game names, the game IDs, and the ratings created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f91036f-2dd5-42f0-a6d3-2fbb37b05484",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "game_indexer = StringIndexer(inputCol=\"game\", outputCol=\"game_id\", handleInvalid=\"skip\")\n",
    "indexed = game_indexer.fit(ratings).transform(ratings)\n",
    "indexed = indexed.withColumn(\"game_id\", col(\"game_id\").cast(\"int\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2598bc8-7fbf-4431-9a79-46e6151d03df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[15]: [Row(user_id=76767, game='Half-Life', rating=1.0, game_id=45),\n Row(user_id=298950, game='Natural Selection 2', rating=1.0, game_id=169),\n Row(user_id=577614, game='Day of Defeat', rating=1.0, game_id=28),\n Row(user_id=975449, game='Borderlands', rating=1.0, game_id=103),\n Row(user_id=975449, game='Swords and Soldiers HD', rating=1.0, game_id=1610)]"
     ]
    }
   ],
   "source": [
    "indexed.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e149cb55-4e5e-4b33-9dcf-29aff1464dec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Aggregating Ratings\n",
    "\n",
    "The final step before training the recommender system was to combine the ratings for `purchase` and `play` for each combination of `user_id` and `game_id` into one unified value. This was done simply by using the `sum` function to add the two ratings (1 for purchase, a logarithmic rating for play) into one total score. Some users had multiple records for playing the same game multiple times (as we noted before), and so this justified the use of aggregation.\n",
    "\n",
    "The new dataframe, `aggRatings`, consisted of the `user_id`, `game_id`, and `rating`, where the user_id and game_id would only have one value for each combination. All of these were numerical values, and could now be passed into the ALS algorithm for collaborative filtering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e39084a7-5033-4db0-8939-1932b9292470",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>user_id</th><th>game_id</th><th>rating</th></tr></thead><tbody><tr><td>57103808</td><td>958</td><td>2.8870696490323797</td></tr><tr><td>110906645</td><td>4</td><td>4.025291075795535</td></tr><tr><td>130950166</td><td>0</td><td>1.0953101798043248</td></tr><tr><td>235692659</td><td>114</td><td>2.6094379124341005</td></tr><tr><td>99264709</td><td>344</td><td>2.5686159179138452</td></tr><tr><td>11403772</td><td>32</td><td>3.681021528714291</td></tr><tr><td>109175936</td><td>104</td><td>7.07993319509559</td></tr><tr><td>118664413</td><td>118</td><td>2.2470322937863827</td></tr><tr><td>92593907</td><td>487</td><td>1.0</td></tr><tr><td>108454875</td><td>385</td><td>3.2512917986064953</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         57103808,
         958,
         2.8870696490323797
        ],
        [
         110906645,
         4,
         4.025291075795535
        ],
        [
         130950166,
         0,
         1.0953101798043248
        ],
        [
         235692659,
         114,
         2.6094379124341005
        ],
        [
         99264709,
         344,
         2.5686159179138452
        ],
        [
         11403772,
         32,
         3.681021528714291
        ],
        [
         109175936,
         104,
         7.07993319509559
        ],
        [
         118664413,
         118,
         2.2470322937863827
        ],
        [
         92593907,
         487,
         1.0
        ],
        [
         108454875,
         385,
         3.2512917986064953
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "user_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "game_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "rating",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "aggRatings = (indexed\n",
    "  .groupBy(\"user_id\", \"game_id\")\n",
    "  .agg(sum_(\"rating\").alias(\"rating\"))\n",
    ")\n",
    "\n",
    "aggRatings.limit(10).display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "710ae275-7293-4180-880a-07669a9da42a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Training the ALS Model and Hyperparameter Tuning\n",
    "\n",
    "Here, we train the collaborative filtering model, with the aim of retrieving a list of games for each user tailored to their specific profile.\n",
    "\n",
    "Firstly, we split the dataset into a training set and a test set using a fixed random seed. The test set takes up 20% of the dataset.\n",
    "\n",
    "We then used the Alternating Least Squares algorithm from Spark MLib, which is well-suited for this type of task where implicit feedback is involved. Hyperparameter tuning is a major part of ensuring the ALS model performs optimally, so we conducted a grid search over several combinations of `alpha` and `regParam`:\n",
    "\n",
    "- `alpha`: [5.0, 10.0, 20.0]\n",
    "- `regParam`: [0.01, 0.1]\n",
    "- `rank` and `maxIter` were fixed (at 6 and 4 respectively) as cycling through these values caused the notebook to run very slowly.\n",
    "\n",
    "We used root mean squared error (RMSE) as an evaluation metric, and whichever `alpha` and `regParam` gave the lowest score would be stored for use as our values for generating final recommendations. These values turned out to be `alpha` = 20 and `regParam` = 0.01, with RMSE = 2.1161, so these were put into the final ALS algorithm with higher `rank` and `maxIter` to finalise the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73442741-2431-4454-895d-9d5e4cdb18ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "trainDF, testDF = aggRatings.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc2b8e2c-2962-47d2-b230-24c1a1635624",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Experiment Tracking with MLflow\n",
    "\n",
    "To manage and track the experiments, MLflow was integrated into the training process. MLflow would automatically log the parameters and RMSE score for each ALS model run, enabling us to compare results efficiently. We could then identify the best model configuration. Recording these metrics is good practice in tasks like these, where reproducibility is key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "200cd1f7-5cc1-42b9-b0fc-3c345defa2c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 5.0, RegParam: 0.01 â†’ RMSE: 2.2521\nAlpha: 5.0, RegParam: 0.1 â†’ RMSE: 2.2713\nAlpha: 10.0, RegParam: 0.01 â†’ RMSE: 2.1791\nAlpha: 10.0, RegParam: 0.1 â†’ RMSE: 2.2031\nAlpha: 20.0, RegParam: 0.01 â†’ RMSE: 2.1161\nAlpha: 20.0, RegParam: 0.1 â†’ RMSE: 2.1333\n"
     ]
    }
   ],
   "source": [
    "alpha_values = [5.0, 10.0, 20.0]\n",
    "reg_values = [0.01, 0.1]\n",
    "\n",
    "best_rmse = float(\"inf\")\n",
    "best_model = None\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "for alpha in alpha_values:\n",
    "    for reg in reg_values:\n",
    "        with mlflow.start_run():\n",
    "            als = ALS(\n",
    "                userCol=\"user_id\",\n",
    "                itemCol=\"game_id\",\n",
    "                ratingCol=\"rating\",\n",
    "                implicitPrefs=True,\n",
    "                coldStartStrategy=\"drop\",\n",
    "                rank=6,\n",
    "                maxIter=4,\n",
    "                alpha=alpha,\n",
    "                regParam=reg\n",
    "            )\n",
    "            model = als.fit(trainDF)\n",
    "\n",
    "            predictions = model.transform(testDF).dropna()\n",
    "            rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "            # MLflow logging\n",
    "            mlflow.log_param(\"alpha\", alpha)\n",
    "            mlflow.log_param(\"regParam\", reg)\n",
    "            mlflow.log_param(\"rank\", 6)\n",
    "            mlflow.log_param(\"maxIter\", 4)\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "            mlflow.spark.log_model(model, \"als_model\")\n",
    "\n",
    "            print(f\"Alpha: {alpha}, RegParam: {reg} â†’ RMSE: {rmse:.4f}\")\n",
    "\n",
    "            # Save best model parameters\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_alpha = alpha\n",
    "                best_reg = reg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f714b33-48b1-466f-868b-f662fbcaae24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "als = ALS(\n",
    "    userCol=\"user_id\",\n",
    "    itemCol=\"game_id\",\n",
    "    ratingCol=\"rating\",\n",
    "    implicitPrefs=True,\n",
    "    coldStartStrategy=\"drop\",\n",
    "    rank=10,\n",
    "    regParam=reg,\n",
    "    alpha=alpha,\n",
    "    maxIter=10\n",
    ")\n",
    "\n",
    "model = als.fit(trainDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb1639e8-0354-421f-9912-2ace494d5e59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+----------+\n|user_id|game_id|            rating|prediction|\n+-------+-------+------------------+----------+\n|   5250|     34|               1.0|0.94050694|\n|  76767|     32| 1.587786664902119| 0.9030746|\n|  76767|     61|3.3702437414678603| 0.9001788|\n|  86540|      4| 3.856470206220483| 0.9188202|\n|  86540|    376|               1.0|0.61156476|\n|  86540|    554|               1.0| 0.4846811|\n|  86540|   1039|               1.0| 0.3096421|\n| 103360|     73|               1.0|0.78958786|\n| 229911|     73|               1.0|0.90568924|\n| 229911|    127|               1.0| 0.8322181|\n+-------+-------+------------------+----------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(testDF).dropna()\n",
    "predictions.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a3e42a6-5fd4-4bed-a3ee-509ee68dcaa0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE = 2.0934\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Test RMSE = {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5aafdfc0-6b8b-4180-bb09-b7fe82bbc9c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Generating Recommendations\n",
    "\n",
    "With the ALS model trained and evaluated, we used it to generate game recommendations for each user. The code returned 10 games for each user in the dataset based on predicted interest.\n",
    "\n",
    "The output was a nested list of game IDs and predicted ratings. To make the data interpretable in a tabular format, we applied the `explode` function, which created 10 rows per user, each with its own game and rating.\n",
    "\n",
    "We then selected and renamed the relevant fields to create a new DataFrame, `flat`, which contains:\n",
    "- `user_id`\n",
    "- `game_id`\n",
    "- `predicted_rating`\n",
    "\n",
    "This structure allows for easier filtering, joining with metadata, and interpretation of results in the following steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2212aff6-2a57-4e04-95fb-39f96c6e2f3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "userRecs = model.recommendForAllUsers(10)\n",
    "\n",
    "# Explode the nested list of game_ids and ratings\n",
    "exploded = userRecs.select(\"user_id\", explode(\"recommendations\").alias(\"rec\"))\n",
    "\n",
    "# Flatten to get user_id, game_id, and rating\n",
    "flat = exploded.select(\n",
    "    col(\"user_id\"),\n",
    "    col(\"rec.game_id\").alias(\"game_id\"),\n",
    "    col(\"rec.rating\").alias(\"predicted_rating\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90f1b859-c4f6-4d34-8945-bbea4d1ceb5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Mapping Recommendations to Game Titles\n",
    "\n",
    "To make the generated recommendations readable, we joined the dataframe `flat` with the original game titles from the indexed dataset. This allows the `user_id` to match up with game titles rather than a vague integer `game_id`.\n",
    "\n",
    "The resulting dataframe, `prettyRecs`, contains `user_id`, `game` and `predicted_rating`, all of which are key features in the recommender system. This final structure enables easy interpretation of the data. The data was ordered by `user_id` and then `predicted_rating` in order to group games by `user_id`, and then rank the games from 1 to 10.\n",
    "\n",
    "Initial analysis of the results reveals that certain game franchises appear very frequently appear the top recommendations across users. This includes popular titles such as â€˜Counter Strikeâ€™, â€˜Half-Lifeâ€™, and â€˜Portalâ€™.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3652ea3b-7e5a-4857-bb44-1bdd6503261e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------------------------------+----------------+\n|user_id|game                                        |predicted_rating|\n+-------+--------------------------------------------+----------------+\n|5250   |Half-Life 2 Lost Coast                      |1.1426936       |\n|5250   |Half-Life 2 Deathmatch                      |1.115324        |\n|5250   |Half-Life 2                                 |1.1047341       |\n|5250   |Portal                                      |1.0443429       |\n|5250   |Counter-Strike Source                       |1.0302583       |\n|5250   |Half-Life 2 Episode One                     |0.9985522       |\n|5250   |Counter-Strike                              |0.9933051       |\n|5250   |Counter-Strike Condition Zero               |0.976385        |\n|5250   |Counter-Strike Condition Zero Deleted Scenes|0.97527313      |\n|5250   |Half-Life 2 Episode Two                     |0.97502095      |\n|76767  |Counter-Strike Source                       |1.134582        |\n|76767  |Half-Life 2 Lost Coast                      |1.111085        |\n|76767  |Half-Life 2 Deathmatch                      |1.0750262       |\n|76767  |Half-Life 2                                 |1.0595078       |\n|76767  |Grand Theft Auto V                          |1.0407896       |\n|76767  |Day of Defeat Source                        |1.0340636       |\n|76767  |Call of Duty Modern Warfare 2               |1.0243146       |\n|76767  |Call of Duty Modern Warfare 2 - Multiplayer |1.0143559       |\n|76767  |Portal                                      |0.9933169       |\n|76767  |Grand Theft Auto IV                         |0.9894933       |\n|86540  |Dota 2                                      |1.1691608       |\n|86540  |Call of Duty Modern Warfare 2 - Multiplayer |1.1378441       |\n|86540  |Call of Duty Modern Warfare 2               |1.1241795       |\n|86540  |Portal                                      |1.1128027       |\n|86540  |Metro 2033                                  |1.0550781       |\n|86540  |Team Fortress 2                             |1.0520911       |\n|86540  |Portal 2                                    |1.0370085       |\n|86540  |Half-Life 2 Episode Two                     |1.0361943       |\n|86540  |Sid Meier's Civilization V                  |1.0250103       |\n|86540  |Half-Life 2 Episode One                     |1.0194294       |\n|103360 |Counter-Strike                              |0.99108845      |\n|103360 |Counter-Strike Condition Zero               |0.9684624       |\n|103360 |Counter-Strike Condition Zero Deleted Scenes|0.9469422       |\n|103360 |Half-Life 2 Deathmatch                      |0.9310697       |\n|103360 |Day of Defeat                               |0.92490864      |\n|103360 |Deathmatch Classic                          |0.9202705       |\n|103360 |Ricochet                                    |0.91458523      |\n|103360 |Half-Life 2 Lost Coast                      |0.91022414      |\n|103360 |Counter-Strike Source                       |0.9054149       |\n|103360 |Day of Defeat Source                        |0.8253749       |\n|144736 |Counter-Strike                              |0.95232433      |\n|144736 |Counter-Strike Condition Zero               |0.92977947      |\n|144736 |Counter-Strike Condition Zero Deleted Scenes|0.9088463       |\n|144736 |Half-Life 2 Deathmatch                      |0.8935633       |\n|144736 |Day of Defeat                               |0.8863225       |\n|144736 |Deathmatch Classic                          |0.8818309       |\n|144736 |Ricochet                                    |0.8765258       |\n|144736 |Half-Life 2 Lost Coast                      |0.8740105       |\n|144736 |Counter-Strike Source                       |0.8735656       |\n|144736 |Day of Defeat Source                        |0.7923825       |\n+-------+--------------------------------------------+----------------+\nonly showing top 50 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Select what we need from indexed\n",
    "game_lookup = indexed.select(\"game_id\", \"game\").distinct()\n",
    "\n",
    "# Join to map game_id to game\n",
    "prettyRecs = flat.join(game_lookup, on=\"game_id\", how=\"left\") \\\n",
    "                 .select(\"user_id\", \"game\", \"predicted_rating\") \\\n",
    "                 .orderBy(\"user_id\", col(\"predicted_rating\").desc())\n",
    "\n",
    "prettyRecs.show(50, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2213e39d-f162-4ebd-adac-cbddeae9a845",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Identifying Franchise-Based Recommendations: Football Manager Case Study\n",
    "\n",
    "To explore the types of games being recommended by the model, we filtered the `prettyRecs` dataframe to show titles which contain the phrase â€˜Football Managerâ€™. There were 6 editions of this game found in the list of top average playtimes per game, given in the EDA section. Usually, when people engage with one edition of this game, they are more inclined to play the others, which makes the franchise a strong candidate for implicit engagement-based recommendations.\n",
    "\n",
    "By displaying these entries, we observed that these titles were often clustered within a single userâ€™s top 10 recommendations. For example, `user_id` = 26813952 had six Football Manager games in their top 10 recommended games.\n",
    "\n",
    "Another block of code was added for extra analysis and observation. Here, we found the users that had at least one Football Manager game in their top 10, and then aggregated these counts to determine the distribution of recommendations. Users with one version of this title usually had 4 or 6 in their recommended top 10, confirming the hypothesis from before.\n",
    "\n",
    "This analysis highlights how strongly the model associates certain users with one specific franchise, reflecting preference patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b56ce959-5f0a-4575-b754-2e4e6690c0b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>user_id</th><th>game</th><th>predicted_rating</th></tr></thead><tbody><tr><td>18604016</td><td>Football Manager 2013</td><td>0.98235375</td></tr><tr><td>18604016</td><td>Football Manager 2012</td><td>0.9562315</td></tr><tr><td>18604016</td><td>Football Manager 2014</td><td>0.92788017</td></tr><tr><td>18604016</td><td>Football Manager 2015</td><td>0.9116237</td></tr><tr><td>23472549</td><td>Football Manager 2013</td><td>0.87253237</td></tr><tr><td>23472549</td><td>Football Manager 2015</td><td>0.83456916</td></tr><tr><td>23472549</td><td>Football Manager 2014</td><td>0.77847433</td></tr><tr><td>23472549</td><td>Football Manager 2012</td><td>0.72247535</td></tr><tr><td>24444528</td><td>Football Manager 2013</td><td>0.3320759</td></tr><tr><td>24444528</td><td>Football Manager 2015</td><td>0.3158424</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         18604016,
         "Football Manager 2013",
         0.98235375
        ],
        [
         18604016,
         "Football Manager 2012",
         0.9562315
        ],
        [
         18604016,
         "Football Manager 2014",
         0.92788017
        ],
        [
         18604016,
         "Football Manager 2015",
         0.9116237
        ],
        [
         23472549,
         "Football Manager 2013",
         0.87253237
        ],
        [
         23472549,
         "Football Manager 2015",
         0.83456916
        ],
        [
         23472549,
         "Football Manager 2014",
         0.77847433
        ],
        [
         23472549,
         "Football Manager 2012",
         0.72247535
        ],
        [
         24444528,
         "Football Manager 2013",
         0.3320759
        ],
        [
         24444528,
         "Football Manager 2015",
         0.3158424
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "user_id",
         "type": "\"integer\""
        },
        {
         "metadata": "{}",
         "name": "game",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "predicted_rating",
         "type": "\"float\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter for games that contain the exact phrase \"Football Manager\"\n",
    "fm_recs = prettyRecs.filter(col(\"game\").contains(\"Football Manager\"))\n",
    "\n",
    "# Show the results\n",
    "fm_recs.limit(10).display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e1ccf4e-1b40-4db2-9295-c2a45e20b098",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n|fm_count|count|\n+--------+-----+\n|       1|   61|\n|       2|   42|\n|       3|   51|\n|       4|  118|\n|       5|   60|\n|       6|  162|\n|       7|   32|\n|       8|   20|\n+--------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# Count how many Football Manager games were recommended per user\n",
    "fm_count_by_user = fm_recs.groupBy(\"user_id\").count().withColumnRenamed(\"count\", \"fm_count\")\n",
    "\n",
    "# Count how many users had N Football Manager games recommended\n",
    "distribution = fm_count_by_user.groupBy(\"fm_count\").count().orderBy(\"fm_count\")\n",
    "distribution.show(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "262de215-3cd1-4af2-a96d-7315da15d7e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Further Model Evaluation\n",
    "\n",
    "Earlier in the notebook, we used RMSE as a metric to evaluate the modelâ€™s predictive accuracy. For recommender systems, it is also important to assess whether the correct items are being predicted near the top of the list. Therefore, three different widely-used ranking metrics were used:\n",
    "\n",
    "- Precision@10: This measures the proportion of recommended games that match the actual list.\n",
    "- Mean Average Precision (MAP): Considers both the precision and the order across all positions.\n",
    "- NDCG@10: Gives higher weight to games found earlier in the list.\n",
    "\n",
    "The results were given as follows:\n",
    "\n",
    "- Precision@10: 0.08504941599281232\n",
    "- MAP: 0.2632924678474174\n",
    "- NDCG@10: 0.3399809231797672\n",
    "\n",
    "This provides evidence of a serviceable recommender system, as implicit data can be very noisy and tricky to predict. For large, sparse datasets like this Steam dataset, this is an acceptable performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58f66772-2745-4b64-8623-5560465ed086",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Top 10 predictions per user\n",
    "preds = (\n",
    "    userRecs\n",
    "    .select(\"user_id\", explode(\"recommendations\").alias(\"rec\"))\n",
    "    .select(\"user_id\", col(\"rec.game_id\").alias(\"game_id\"))\n",
    "    .groupBy(\"user_id\")\n",
    "    .agg(collect_list(\"game_id\").alias(\"preds\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5718a651-e02f-4274-8063-b67edbbb6341",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Actual games interacted with per user\n",
    "labels = (\n",
    "    testDF\n",
    "    .groupBy(\"user_id\")\n",
    "    .agg(collect_list(\"game_id\").alias(\"labels\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1867e4dd-a984-4d4a-b42f-207192b1e37a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/spark/python/pyspark/sql/context.py:165: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10: 0.08504941599281232\nMAP: 0.2632924678474174\nNDCG@10: 0.3399809231797672\n"
     ]
    }
   ],
   "source": [
    "# Create RDD of predictions and labels\n",
    "metrics_rdd = (\n",
    "    preds\n",
    "    .join(labels, \"user_id\")\n",
    "    .rdd\n",
    "    .map(lambda row: (row.preds, row.labels))\n",
    ")\n",
    "\n",
    "# Evaluate ranking metrics from predictions\n",
    "metrics = RankingMetrics(metrics_rdd)\n",
    "print(\"Precision@10:\", metrics.precisionAt(10))\n",
    "print(\"MAP:\", metrics.meanAveragePrecision)\n",
    "print(\"NDCG@10:\", metrics.ndcgAt(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88e8b2d9-a612-479b-a861-4db67c7124c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Conclusion\n",
    "\n",
    "In this project, we created a collaborative filtering recommender system using implicit feedback data from Steam. The system was built using ALS and trained on a real dataset containing 200,000 user-game interactions.\n",
    "\n",
    "Data preprocessing steps were employed, such as deduplicating various rows of data and normalising play hours. Player behaviour was analysed and converted into a singular â€˜ratingâ€™ value, and categorical features were converted into numeric indices for matrix factorisation.\n",
    "\n",
    "We then applied hyperparameter tuning and trained the model, before evaluating its performance with different types of metrics such as RMSE and Precision@10. This verified that the model was recommending games that align with user interests.\n",
    "\n",
    "One case study was that of the Football Manager franchise. The model effectively grouped titles of this series within the same user IDs, reflecting patterns that often take place within gaming culture. The same games would appear at the top of most lists recommended to users, such as â€˜Counter Strikeâ€™, so there is still room for improvement. The model would benefit from explicit data and more hyperparameter tuning with `rank` and `maxIter`. Nevertheless, the recommender system performed to an acceptable level and there were obvious signs of success, while being a scalable approach.\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "BDTT_Assignment2_Task2_final_trimmed",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}